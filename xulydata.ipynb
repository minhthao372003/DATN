{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã ghép tất cả các file thành công và lưu vào merged_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Danh sách các file Excel cần ghép\n",
    "files = [\n",
    "    'D:/data/datagoc/HOSE.xlsx',\n",
    "    'D:/data/datagoc/HOSE1.xlsx',\n",
    "    'D:/data/datagoc/HOSE2.xlsx',\n",
    "    'D:/data/datagoc/HOSE3.xlsx',\n",
    "    'D:/data/datagoc/HOSE4.xlsx'\n",
    "    # Thêm các file khác nếu có\n",
    "]\n",
    "\n",
    "# List để lưu trữ các DataFrame từ mỗi file\n",
    "df_list = []\n",
    "\n",
    "# Lặp qua từng file và đọc tất cả các sheet trong mỗi file\n",
    "for file in files:\n",
    "    xls = pd.ExcelFile(file)\n",
    "    for sheet in xls.sheet_names:\n",
    "        df = pd.read_excel(xls, sheet_name=sheet)\n",
    "        df_list.append(df)\n",
    "\n",
    "# Ghép tất cả các DataFrame lại với nhau\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Lưu DataFrame kết quả vào một file Excel mới\n",
    "final_df.to_excel('D:/data/HOSEfile.xlsx', index=False)\n",
    "\n",
    "print(\"Đã ghép tất cả các file thành công và lưu vào merged_data.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thay thế các giá trị trong cột 'san' và lưu vào HNXfile_updated.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đường dẫn đến file Excel\n",
    "file_path = 'D:/data/HOSEfile.xlsx'  # Đảm bảo đường dẫn này chính xác\n",
    "\n",
    "# Đọc file Excel\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Kiểm tra nếu cột 'san' tồn tại và thay thế giá trị của nó bằng 'HNXIndex'\n",
    "if 'san' in df.columns:\n",
    "    df['san'] = 'VNINDEX'\n",
    "\n",
    "# Lưu lại file Excel mới\n",
    "df.to_excel('D:/data/HOSEfile_updated.xlsx', index=False)\n",
    "\n",
    "print(\"Đã thay thế các giá trị trong cột 'san' và lưu vào HNXfile_updated.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File đã được lưu với tên 'HOSEfile_with_nganh.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đường dẫn đến các file Excel\n",
    "hose_file_path = 'D:/data/HOSEfile.xlsx'\n",
    "nganh_file_path = 'D:/data/nganh2.xlsx'\n",
    "\n",
    "# Đọc các file Excel\n",
    "df_hose = pd.read_excel(hose_file_path)\n",
    "df_nganh = pd.read_excel(nganh_file_path)\n",
    "\n",
    "# Ghép dữ liệu từ 2 file dựa trên cột 'ma' (mã công ty)\n",
    "df_merged = pd.merge(df_hose, df_nganh[['ma', 'nganh']], on='ma', how='left', suffixes=('', '_from_nganh2'))\n",
    "\n",
    "# Điền dữ liệu vào cột 'nganh' từ df_nganh nếu nó bị thiếu trong df_hose\n",
    "df_merged['nganh'] = df_merged['nganh'].combine_first(df_merged['nganh_from_nganh2'])\n",
    "\n",
    "# Xóa cột phụ 'nganh_from_nganh2' sau khi điền dữ liệu\n",
    "df_merged.drop(columns=['nganh_from_nganh2'], inplace=True)\n",
    "\n",
    "# Lưu file Excel đã cập nhật\n",
    "df_merged.to_excel('D:/data/HOSEfile_with_nganh.xlsx', index=False)\n",
    "\n",
    "print(\"File đã được lưu với tên 'HOSEfile_with_nganh.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được làm sạch và lưu vào file 'updated_file2_with_filled_chisonganh.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel files\n",
    "updated_df = pd.read_excel(\"D:/data/HOSEfile.xlsx\")  # Update the path as needed\n",
    "nganh_df = pd.read_excel(\"D:/data/nganh.xlsx\")            # Update the path as needed\n",
    "\n",
    "# Standardize the column names by converting to lowercase and stripping spaces\n",
    "updated_df.columns = updated_df.columns.str.lower().str.strip()\n",
    "nganh_df.columns = nganh_df.columns.str.lower().str.strip()\n",
    "\n",
    "# Standardize the 'nganh' column and date columns to ensure matching works correctly\n",
    "updated_df['nganh'] = updated_df['nganh'].str.lower().str.strip()\n",
    "nganh_df['nganh'] = nganh_df['nganh'].str.lower().str.strip()\n",
    "updated_df['ngay'] = pd.to_datetime(updated_df['ngay'], errors='coerce')\n",
    "nganh_df['ngay'] = pd.to_datetime(nganh_df['ngay'], errors='coerce')\n",
    "\n",
    "# Merge updated_df with nganh_df on 'ngay' and 'nganh' to get 'chisonganh'\n",
    "merged_df = updated_df.merge(\n",
    "    nganh_df[['nganh', 'ngay', 'chisonganh']],\n",
    "    on=['nganh', 'ngay'],\n",
    "    how='left',\n",
    "    suffixes=('', '_new')\n",
    ")\n",
    "\n",
    "# Fill the 'chisonganh' column in updated_df with values from nganh_df\n",
    "merged_df['chisonganh'] = merged_df['chisonganh'].combine_first(merged_df['chisonganh_new'])\n",
    "\n",
    "# Drop the temporary 'chisonganh_new' column used for merging\n",
    "final_cleaned_data = merged_df.drop(columns=['chisonganh_new'])\n",
    "\n",
    "# Save the updated file with filled 'chisonganh' column\n",
    "final_cleaned_data.to_excel(\"D:/data/HOSE_chisonganh.xlsx\", index=False)\n",
    "\n",
    "print(\"Dữ liệu đã được làm sạch và lưu vào file 'updated_file2_with_filled_chisonganh.xlsx'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được làm sạch và lưu vào file 'D:/data/HOSE_index.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel files\n",
    "updated_df = pd.read_excel(\"D:/data/HOSE.xlsx\")  # Update the path as needed\n",
    "index_df = pd.read_excel(\"D:/data/Index.xlsx\")  # Update the path as needed\n",
    "\n",
    "# Standardize the column names by converting to lowercase and stripping spaces\n",
    "updated_df.columns = updated_df.columns.str.lower().str.strip()\n",
    "index_df.columns = index_df.columns.str.lower().str.strip()\n",
    "\n",
    "# Ensure 'san' column is treated as string, handle missing values\n",
    "updated_df['san'] = updated_df['san'].astype(str).str.lower().str.strip()\n",
    "index_df['san'] = index_df['san'].astype(str).str.lower().str.strip()\n",
    "\n",
    "# Convert 'ngay' column to datetime and handle invalid parsing with 'coerce'\n",
    "updated_df['ngay'] = pd.to_datetime(updated_df['ngay'], errors='coerce')\n",
    "index_df['ngay'] = pd.to_datetime(index_df['ngay'], errors='coerce')\n",
    "\n",
    "# Merge updated_df with index_df on 'ngay' and 'san' to get 'index'\n",
    "merged_df = updated_df.merge(\n",
    "    index_df[['san', 'ngay', 'index']],\n",
    "    on=['san', 'ngay'],\n",
    "    how='left',\n",
    "    suffixes=('', '_new')  # Handle potential duplicate column names\n",
    ")\n",
    "\n",
    "# Fill the 'index' column in updated_df with values from index_df (from 'index_new')\n",
    "merged_df['index'] = merged_df['index'].combine_first(merged_df['index_new'])\n",
    "\n",
    "# Drop the temporary 'index_new' column used for merging\n",
    "final_cleaned_data = merged_df.drop(columns=['index_new'])\n",
    "\n",
    "# Save the updated file with filled 'index' column\n",
    "output_file = \"D:/data/HOSE_index.xlsx\"\n",
    "final_cleaned_data.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Dữ liệu đã được làm sạch và lưu vào file '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset saved as 'D:/data/HOSE_clean.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_excel(\"D:/data/HOSE.xlsx\")  # Update the path as needed\n",
    "\n",
    "# Standardize the column names by converting to lowercase and stripping spaces\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "# Define financial sector keywords to filter out\n",
    "financial_keywords = [\n",
    "    'quỹ ủy thác bđs', 'quản lý tài sản', 'tài chính cá nhân', 'tài chính đặc biệt', \n",
    "    'môi giới chứng khoán', 'cầm cố', 'quỹ đầu tư', 'ngân hàng', 'bảo hiểm phức hợp',\n",
    "    'môi giới bảo hiểm', 'bảo hiểm phi nhân thọ', 'tái bảo hiểm', 'bảo hiểm nhân thọ'\n",
    "]\n",
    "\n",
    "# Filter out rows where 'nganh' contains any of the financial keywords\n",
    "non_financial_df = df[~df['nganh'].str.lower().str.contains('|'.join(financial_keywords), na=False)]\n",
    "\n",
    "# Update the path to a valid location on your computer\n",
    "output_path = \"D:/data/HOSE_clean.xlsx\"  # Ensure the directory exists\n",
    "\n",
    "# Save the filtered DataFrame to a new Excel file\n",
    "non_financial_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Filtered dataset saved as '{output_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng công ty trong tệp là: 293\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_excel(\"D:/data/HNX_clean.xlsx\")  # Update the path as needed\n",
    "\n",
    "# Standardize the column names by converting to lowercase and stripping spaces\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "# Count the number of unique companies based on the 'ma' column\n",
    "number_of_companies = df['ma'].nunique()\n",
    "\n",
    "print(f\"Số lượng công ty trong tệp là: {number_of_companies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng công ty trong tệp là: 351\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_excel(\"D:/data/HOSE_clean.xlsx\")  # Update the path as needed\n",
    "\n",
    "# Standardize the column names by converting to lowercase and stripping spaces\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "# Count the number of unique companies based on the 'ma' column\n",
    "number_of_companies = df['ma'].nunique()\n",
    "\n",
    "print(f\"Số lượng công ty trong tệp là: {number_of_companies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng công ty trong tệp là: 639\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"D:/data/SYNCH_no2024.csv\")  # Update the path as needed\n",
    "\n",
    "# Standardize the column names by converting to lowercase and stripping spaces\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "# Count the number of unique companies based on the 'ma' column\n",
    "number_of_companies = df['ma'].nunique()\n",
    "\n",
    "print(f\"Số lượng công ty trong tệp là: {number_of_companies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được ghép và lưu thành công vào D:/data/alldata.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đường dẫn đến các tệp Excel\n",
    "hnx_file = 'D:/data/HNX_clean.xlsx'  # Thay bằng đường dẫn đến file HNX của bạn\n",
    "hose_file = 'D:/data/HOSE_clean.xlsx'  # Thay bằng đường dẫn đến file HOSE của bạn\n",
    "\n",
    "# Đọc dữ liệu từ các tệp Excel\n",
    "hnx_data = pd.read_excel(hnx_file)\n",
    "hose_data = pd.read_excel(hose_file)\n",
    "\n",
    "# Ghép hai bảng dữ liệu lại với nhau\n",
    "combined_data = pd.concat([hnx_data, hose_data], ignore_index=True)\n",
    "\n",
    "# Xuất dữ liệu ghép thành tệp CSV\n",
    "output_csv = 'D:/data/alldata.csv'\n",
    "combined_data.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f'Dữ liệu đã được ghép và lưu thành công vào {output_csv}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: statsmodels in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (0.14.3)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from statsmodels) (2.1.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from statsmodels) (1.14.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from statsmodels) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: six in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhthao372003\\AppData\\Local\\Temp\\ipykernel_17896\\1787543578.py:19: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df['ret'] = df.groupby('ma')['giadongcuadc'].pct_change()\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SYNCH results by year have been saved as 'synch_results_by_year.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"D:/data/combined_HNX_HOSE.csv\")  # Update with the correct path\n",
    "\n",
    "# Standardize the column names by converting to lowercase and stripping spaces\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "# Convert 'ngay' to datetime and extract year\n",
    "df['ngay'] = pd.to_datetime(df['ngay'], errors='coerce')\n",
    "df['year'] = df['ngay'].dt.year\n",
    "\n",
    "# Sort data by 'ma', 'year', and 'ngay' to calculate returns correctly\n",
    "df = df.sort_values(by=['ma', 'year', 'ngay'])\n",
    "\n",
    "# Calculate daily returns for each stock, market, and industry index\n",
    "df['ret'] = df.groupby('ma')['giadongcuadc'].pct_change()\n",
    "df['mktret'] = df['index'].pct_change()\n",
    "df['indret'] = df.groupby('ma')['chisonganh'].pct_change()\n",
    "\n",
    "# Drop rows with NaN values due to initial return calculation\n",
    "df = df.dropna(subset=['ret', 'mktret', 'indret'])\n",
    "\n",
    "# Prepare a DataFrame to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each company and year combination\n",
    "for (ma, year), group in df.groupby(['ma', 'year']):\n",
    "    # Create lagged market and industry returns\n",
    "    group['mktret_lag'] = group['mktret'].shift(1)\n",
    "    group['indret_lag'] = group['indret'].shift(1)\n",
    "    \n",
    "    # Drop rows with NaN due to lagging\n",
    "    group = group.dropna(subset=['mktret_lag', 'indret_lag'])\n",
    "    \n",
    "    # Define the regression model\n",
    "    X = group[['mktret', 'mktret_lag', 'indret', 'indret_lag']]\n",
    "    X = sm.add_constant(X)  # Add a constant term for the regression\n",
    "    y = group['ret']\n",
    "    \n",
    "    # Run the regression\n",
    "    if not X.empty:\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        rsquared = model.rsquared\n",
    "        synch = np.log(rsquared / (1 - rsquared)) if rsquared < 1 else np.nan\n",
    "        \n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'ma': ma,\n",
    "            'year': year,\n",
    "            'R_squared': rsquared,\n",
    "            'SYNCH': synch\n",
    "        })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\"D:/data/synch_results_by_year2.csv\", index=False)\n",
    "\n",
    "print(\"The SYNCH results by year have been saved as 'synch_results_by_year.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được lọc và lưu vào: D:/data/SYNCH_no2024.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "file_path = 'D:/data/synch_results_with_BIG4.csv'  # Thay bằng đường dẫn file của bạn\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Giả sử cột 'year' chứa năm ở định dạng chuỗi, chúng ta chuyển đổi nó sang dạng số nguyên\n",
    "data['year'] = pd.to_numeric(data['year'], errors='coerce')\n",
    "\n",
    "# Loại bỏ các dòng có giá trị năm là 2024\n",
    "filtered_data = data[data['year'] != 2024]\n",
    "\n",
    "# Lưu dữ liệu đã lọc vào file CSV mới\n",
    "output_file_path = 'D:/data/SYNCH_no2024.csv'  # Thay bằng tên file bạn muốn lưu\n",
    "filtered_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f'Dữ liệu đã được lọc và lưu vào: {output_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được xuất ra file: D:/data/combined_HNX_HOSE.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đường dẫn tới các file Excel\n",
    "hnx_file_path = 'D:/data/HNX_clean.xlsx'  # Thay bằng đường dẫn tới tệp HNX_clean.xlsx của bạn\n",
    "hose_file_path = 'D:/data/HOSE_clean.xlsx'  # Thay bằng đường dẫn tới tệp HOSE_clean.xlsx của bạn\n",
    "\n",
    "# Đọc dữ liệu từ các file Excel\n",
    "hnx_data = pd.read_excel(hnx_file_path, engine='openpyxl')\n",
    "hose_data = pd.read_excel(hose_file_path, engine='openpyxl')\n",
    "\n",
    "# Kết hợp hai bảng dữ liệu\n",
    "combined_data = pd.concat([hnx_data, hose_data], ignore_index=True)\n",
    "\n",
    "# Xuất dữ liệu kết hợp ra tệp CSV\n",
    "output_csv_path = 'D:/data/combined_HNX_HOSE.csv'  # Tên file CSV mà bạn muốn xuất ra\n",
    "combined_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f'Dữ liệu đã được xuất ra file: {output_csv_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được ghép và lưu vào file: D:/data/synch_results_with_BIG4.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đường dẫn tới các file CSV\n",
    "merged_file_path = 'D:/data/synch_merged.csv'  # Thay bằng đường dẫn tới file synch_merged.csv\n",
    "results_file_path = 'D:/data/synch_results_by_year2.csv'  # Thay bằng đường dẫn tới file synch_results_by_year2.csv\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "merged_data = pd.read_csv(merged_file_path)\n",
    "results_data = pd.read_csv(results_file_path)\n",
    "\n",
    "# Ghép cột \"BIG4\" từ file \"synch_merged.csv\" sang file \"synch_results_by_year2.csv\" dựa trên cột \"ma\" và \"year\"\n",
    "merged_with_big4 = pd.merge(results_data, merged_data[['ma', 'year', 'BIG4']], on=['ma', 'year'], how='left')\n",
    "\n",
    "# Xuất dữ liệu đã ghép ra file CSV mới\n",
    "output_csv_with_big4 = 'D:/data/synch_results_with_BIG4.csv'  # Đường dẫn xuất file CSV mới\n",
    "merged_with_big4.to_csv(output_csv_with_big4, index=False)\n",
    "\n",
    "print(f'Dữ liệu đã được ghép và lưu vào file: {output_csv_with_big4}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ hai file CSV\n",
    "file_combined = 'D:/data/combined_HNX_HOSE.csv'\n",
    "file_synch = 'D:/data/SYNCH_no2024.csv'\n",
    "\n",
    "# Đọc file combined_HNX_HOSE.csv\n",
    "df_combined = pd.read_csv(file_combined)\n",
    "\n",
    "# Đọc file SYNCH_no2024.csv\n",
    "df_synch = pd.read_csv(file_synch)\n",
    "\n",
    "# Chuyển cột 'ngay' thành kiểu datetime\n",
    "df_combined['ngay'] = pd.to_datetime(df_combined['ngay'])\n",
    "\n",
    "# Thêm cột 'year' để trích xuất năm từ cột 'ngay'\n",
    "df_combined['year'] = df_combined['ngay'].dt.year\n",
    "\n",
    "# Tính tổng khối lượng giao dịch theo từng mã cổ phiếu cho mỗi năm\n",
    "vol_per_year = df_combined.groupby(['ma', 'year'])['khoiluong'].sum().reset_index()\n",
    "\n",
    "# Đổi tên cột 'khoiluong' thành 'VOL'\n",
    "vol_per_year.rename(columns={'khoiluong': 'VOL'}, inplace=True)\n",
    "\n",
    "# Ghép kết quả vào file SYNCH_no2024.csv dựa trên 'ma' và 'year'\n",
    "df_merged = pd.merge(df_synch, vol_per_year, on=['ma', 'year'], how='left')\n",
    "\n",
    "# Lưu lại file đã ghép vào file CSV mới\n",
    "df_merged.to_csv('D:/data/SYNCH_no2024_with_VOL.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ hai file CSV\n",
    "file_size_calculated = 'D:/data/datagoc/SIZE_calculated.csv'\n",
    "file_synch = 'D:/data/SYNCH_no2024.csv'\n",
    "\n",
    "# Đọc file SIZE_calculated.csv\n",
    "df_size = pd.read_csv(file_size_calculated)\n",
    "\n",
    "# Đọc file SYNCH_no2024.csv\n",
    "df_synch = pd.read_csv(file_synch)\n",
    "\n",
    "# Chuyển dữ liệu SIZE từ cột năm thành hàng (unpivot)\n",
    "df_size_melted = pd.melt(df_size, id_vars=['ma'], var_name='year', value_name='SIZE')\n",
    "\n",
    "# Đảm bảo cột 'year' là kiểu số nguyên để khớp với file SYNCH_no2024.csv\n",
    "df_size_melted['year'] = df_size_melted['year'].astype(int)\n",
    "\n",
    "# Ghép dữ liệu SIZE vào file SYNCH_no2024.csv dựa trên 'ma' và 'year'\n",
    "df_merged_size = pd.merge(df_synch, df_size_melted, on=['ma', 'year'], how='left')\n",
    "\n",
    "# Lưu lại file đã ghép vào file CSV mới\n",
    "df_merged_size.to_csv('D:/data/SYNCH_no2024_with_SIZE.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ hai file CSV\n",
    "file_synch = 'D:/data/SYNCH_no2024.csv'\n",
    "file_lev = 'D:/data/LEV.csv'\n",
    "\n",
    "# Đọc file SYNCH_no2024.csv\n",
    "df_synch = pd.read_csv(file_synch)\n",
    "\n",
    "# Đọc file LEV.csv\n",
    "df_lev = pd.read_csv(file_lev)\n",
    "\n",
    "# Ghép dữ liệu cột LEV từ file LEV.csv vào file SYNCH_no2024.csv dựa trên 'ma' và 'year'\n",
    "df_merged_lev = pd.merge(df_synch, df_lev[['ma', 'year', 'LEV']], on=['ma', 'year'], how='left')\n",
    "\n",
    "# Lưu lại file đã ghép vào file CSV mới\n",
    "df_merged_lev.to_csv('D:/data/SYNCH_no2024_with_LEV.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\minhthao372003\\AppData\\Local\\Temp\\ipykernel_17896\\2438245787.py:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df_stdroa_melted['year'] = df_stdroa_melted['year'].str.extract('(\\d+)').astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ hai file CSV\n",
    "file_synch = 'D:/data/SYNCH_no2024.csv'\n",
    "file_stdroa = 'D:/data/datagoc/STDROA.csv'\n",
    "\n",
    "# Đọc file SYNCH_no2024.csv\n",
    "df_synch = pd.read_csv(file_synch)\n",
    "\n",
    "# Đọc file STDROA.csv\n",
    "df_stdroa = pd.read_csv(file_stdroa)\n",
    "\n",
    "# Chuyển đổi dữ liệu từ file STDROA.csv từ dạng cột năm thành dạng hàng (unpivot)\n",
    "df_stdroa_melted = pd.melt(df_stdroa, id_vars=['ma'], var_name='year', value_name='S_ROA')\n",
    "\n",
    "# Chuyển đổi cột 'year' trong df_stdroa_melted để khớp với cột 'year' trong df_synch\n",
    "df_stdroa_melted['year'] = df_stdroa_melted['year'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Ghép dữ liệu 'S_ROA' vào file SYNCH_no2024.csv dựa trên 'ma' và 'year'\n",
    "df_merged = pd.merge(df_synch, df_stdroa_melted[['ma', 'year', 'S_ROA']], on=['ma', 'year'], how='left')\n",
    "\n",
    "# Lưu lại kết quả vào file CSV mới\n",
    "df_merged.to_csv('D:/data/SYNCH_no2024_with_S_ROA.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\minhthao372003\\AppData\\Local\\Temp\\ipykernel_17896\\2044977028.py:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df_mb_melted['year'] = df_mb_melted['year'].str.extract('(\\d+)').astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ hai file CSV\n",
    "file_synch = 'D:/data/SYNCH_no2024.csv'\n",
    "file_mb = 'D:/data/datagoc/MB_calculated.csv'\n",
    "\n",
    "# Đọc file SYNCH_no2024.csv\n",
    "df_synch = pd.read_csv(file_synch)\n",
    "\n",
    "# Đọc file MB_calculated.csv\n",
    "df_mb = pd.read_csv(file_mb)\n",
    "\n",
    "# Chuyển đổi dữ liệu MB_calculated.csv từ dạng cột năm thành dạng hàng (unpivot)\n",
    "df_mb_melted = pd.melt(df_mb, id_vars=['ma'], var_name='year', value_name='M/B')\n",
    "\n",
    "# Chuyển đổi 'year' trong df_mb_melted để khớp với cột 'year' trong df_synch\n",
    "df_mb_melted['year'] = df_mb_melted['year'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Ghép dữ liệu 'M/B' vào file SYNCH_no2024.csv dựa trên 'ma' và 'year'\n",
    "df_merged_mb = pd.merge(df_synch, df_mb_melted[['ma', 'year', 'M/B']], on=['ma', 'year'], how='left')\n",
    "\n",
    "# Lưu lại kết quả vào file CSV mới\n",
    "df_merged_mb.to_csv('D:/data/SYNCH_no2024_with_MB.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ hai file CSV\n",
    "file_synch = 'D:/data/SYNCH_no2024.csv'\n",
    "file_indn = 'D:/data/datagoc/INDNUM.csv'\n",
    "\n",
    "# Đọc file SYNCH_no2024.csv\n",
    "df_synch = pd.read_csv(file_synch)\n",
    "\n",
    "# Đọc file INDNUM.csv\n",
    "df_indn = pd.read_csv(file_indn)\n",
    "\n",
    "# Ghép dữ liệu 'INDNUM' vào file SYNCH_no2024.csv dựa trên 'ma' và 'year'\n",
    "df_merged_indn = pd.merge(df_synch, df_indn[['ma', 'year', 'INDNUM']], on=['ma', 'year'], how='left')\n",
    "\n",
    "# Đổi tên cột 'INDNUM' thành 'INDN'\n",
    "df_merged_indn.rename(columns={'INDNUM': 'INDN'}, inplace=True)\n",
    "\n",
    "# Lưu lại file đã ghép vào file CSV mới\n",
    "df_merged_indn.to_csv('D:/data/SYNCH_no2024_with_INDNUM.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ hai file CSV\n",
    "file_synch = 'D:/data/SYNCH_no2024.csv'\n",
    "file_indsize = 'D:/data/datagoc/INDSIZE_calculated.csv'\n",
    "\n",
    "# Đọc file SYNCH_no2024.csv\n",
    "df_synch = pd.read_csv(file_synch)\n",
    "\n",
    "# Đọc file INDSIZE_calculated.csv\n",
    "df_indsize = pd.read_csv(file_indsize)\n",
    "\n",
    "# Ghép dữ liệu 'INDSIZE' vào file SYNCH_no2024.csv dựa trên 'ma' và 'year'\n",
    "df_merged_inds = pd.merge(df_synch, df_indsize[['ma', 'year', 'INDSIZE']], on=['ma', 'year'], how='left')\n",
    "\n",
    "# Đổi tên cột 'INDSIZE' thành 'INDS'\n",
    "df_merged_inds.rename(columns={'INDSIZE': 'INDS'}, inplace=True)\n",
    "\n",
    "# Lưu lại file đã ghép vào file CSV mới\n",
    "df_merged_inds.to_csv('D:/data/SYNCH_no2024_with_INDS.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu YearDummies đã được tính toán và lưu vào D:/data/SYNCH_no2024_with_YearDummies.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Bước 1: Tải tệp dữ liệu\n",
    "synch_2023_file_path = 'D:/data/SYNCH_no2024.csv'  # Thay bằng đường dẫn đến file SYNCH_2023 của bạn\n",
    "\n",
    "# Đọc dữ liệu\n",
    "synch_2023_data = pd.read_csv(synch_2023_file_path)\n",
    "\n",
    "# Bước 2: Tạo các biến YearDummies cho từng năm với giá trị 0 và 1\n",
    "year_dummies = pd.get_dummies(synch_2023_data['year'], prefix='Year')\n",
    "\n",
    "# Đảm bảo các biến giả là số nguyên (0 và 1)\n",
    "year_dummies = year_dummies.astype(int)\n",
    "\n",
    "# Bước 3: Ghép các biến YearDummies với dữ liệu gốc\n",
    "synch_2023_with_dummies = pd.concat([synch_2023_data, year_dummies], axis=1)\n",
    "\n",
    "# Bước 4: Lưu dữ liệu đã ghép vào tệp CSV mới\n",
    "output_with_year_dummies_path = 'D:/data/SYNCH_no2024_with_YearDummies.csv'  # Đường dẫn lưu tệp kết quả\n",
    "synch_2023_with_dummies.to_csv(output_with_year_dummies_path, index=False)\n",
    "\n",
    "print(f\"Dữ liệu YearDummies đã được tính toán và lưu vào {output_with_year_dummies_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thêm cột 'khoinganh' và lưu file thành công.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ file CSV của công ty\n",
    "company_data = pd.read_csv('D:/data/combined_HNX_HOSE.csv')\n",
    "\n",
    "# Đọc dữ liệu phân loại ngành từ file Excel\n",
    "industry_data = pd.read_excel('D:/data/datagoc/nganh_detinh_khoinganh.xlsx')\n",
    "\n",
    "# Tạo một dictionary để ánh xạ từ ngành (nganh) sang phân ngành (khoinganh)\n",
    "industry_mapping = {}\n",
    "\n",
    "# Lặp qua các cột của industry_data để tạo ánh xạ\n",
    "for column in industry_data.columns:\n",
    "    industries_in_category = industry_data[column].dropna().tolist()\n",
    "    for industry in industries_in_category:\n",
    "        # Chuẩn hóa dữ liệu để đảm bảo nhất quán\n",
    "        industry_mapping[industry.strip().lower()] = column\n",
    "\n",
    "# Chuẩn hóa cột 'nganh' của company_data để ánh xạ đúng\n",
    "company_data['nganh'] = company_data['nganh'].str.strip().str.lower()\n",
    "\n",
    "# Áp dụng ánh xạ để tạo cột 'khoinganh' mới\n",
    "company_data['khoinganh'] = company_data['nganh'].map(industry_mapping)\n",
    "\n",
    "# Lưu dữ liệu đã cập nhật thành file CSV mới\n",
    "company_data.to_csv('D:/data/combined_with_khoinganh.csv', index=False)\n",
    "\n",
    "print(\"Đã thêm cột 'khoinganh' và lưu file thành công.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thêm cột 'khoinganh' và lưu file thành công.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ cả hai file\n",
    "company_data = pd.read_csv('D:/data/combined_with_khoinganh.csv')\n",
    "synch_data = pd.read_csv('D:/data/SYNCH_no2024_with_YearDummies.csv')\n",
    "\n",
    "# Thực hiện ghép dữ liệu dựa trên cột \"ma\" (mã công ty)\n",
    "synch_data_with_khoinganh = pd.merge(synch_data, company_data[['ma', 'khoinganh']], on='ma', how='left')\n",
    "\n",
    "# Lưu kết quả vào file mới\n",
    "synch_data_with_khoinganh.to_csv('D:/data/SYNCH_with_khoinganh.csv', index=False)\n",
    "\n",
    "print(\"Đã thêm cột 'khoinganh' và lưu file thành công.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thêm các cột 'Industry_' và lưu file thành công.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ file \"SYNCH_with_khoinganh.csv\"\n",
    "synch_with_khoinganh = pd.read_csv('D:/data/SYNCH_with_khoinganh.csv')\n",
    "\n",
    "# Danh sách các ngành để tạo cột \"Industry_\"\n",
    "industry_categories = [\"Daukhi\", \"Nguyenvatlieu\", \"Hangtieudung\", \"Duocphamvayte\", \n",
    "                       \"Dichvutieudung\", \"Vienthong\", \"Tienichcongdong\", \n",
    "                       \"Congnghethongtin\", \"Taichinh\"]\n",
    "\n",
    "# Tạo các cột \"Industry_\" với giá trị 1 hoặc 0 tùy theo giá trị của \"khoinganh\"\n",
    "for industry in industry_categories:\n",
    "    column_name = f\"Industry_{industry}\"\n",
    "    synch_with_khoinganh[column_name] = synch_with_khoinganh['khoinganh'].apply(lambda x: 1 if x == industry else 0)\n",
    "\n",
    "# Lưu lại file đã cập nhật\n",
    "synch_with_khoinganh.to_csv('D:/data/SYNCH_with_IndustryDummies.csv', index=False)\n",
    "\n",
    "print(\"Đã thêm các cột 'Industry_' và lưu file thành công.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhthao372003\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Feature       VIF\n",
      "0             const       inf\n",
      "1              BIG4  1.184862\n",
      "2               VOL  1.297109\n",
      "3              SIZE  1.956162\n",
      "4               LEV  1.220262\n",
      "5             S_ROA  1.149347\n",
      "6               M/B  1.419031\n",
      "7              INDN  2.057616\n",
      "8              INDS  2.794915\n",
      "9    Year_2016_2019       inf\n",
      "10   Year_2020_2023       inf\n",
      "11  Industry_Group1       inf\n",
      "12  Industry_Group2       inf\n",
      "13  Industry_Group3       inf\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Tính VIF cho các biến trong ma trận X (không bao gồm hằng số)\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('D:/data/SYNCH_official.csv')\n",
    "data['Year_2016_2019'] = data[['Year_2016', 'Year_2017', 'Year_2018', 'Year_2019']].sum(axis=1)\n",
    "data['Year_2020_2023'] = data[['Year_2020', 'Year_2021', 'Year_2022', 'Year_2023']].sum(axis=1)\n",
    "data.to_csv('D:/data/updated_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('D:/data/updated_data.csv')\n",
    "data['Industry_Group1'] = data[['Industry_Daukhi', 'Industry_Nguyenvatlieu', 'Industry_Hangtieudung']].sum(axis=1)\n",
    "data['Industry_Group2'] = data[['Industry_Duocphamvayte', 'Industry_Dichvutieudung', 'Industry_Tienichcongdong']].sum(axis=1)\n",
    "data['Industry_Group3'] = data[['Industry_Vienthong', 'Industry_Congnghethongtin', 'Industry_Taichinh']].sum(axis=1)\n",
    "data.to_csv('D:/data/updated_full_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (2.1.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_excel() got an unexpected keyword argument 'chunksize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Đọc file Excel theo từng phần\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSheet1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Chuyển cột 'ngay' sang định dạng datetime\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mngay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mngay\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Lấy năm từ cột 'ngay'\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: read_excel() got an unexpected keyword argument 'chunksize'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đường dẫn đến file Excel của bạn\n",
    "file_path = \"D:/data/khoiluong_HOSE.xlsx\"\n",
    "\n",
    "# Kích thước mỗi chunk\n",
    "chunk_size = 5000  # Số dòng đọc mỗi lần\n",
    "\n",
    "# DataFrame để lưu kết quả\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Đọc file Excel theo từng phần\n",
    "for chunk in pd.read_excel(file_path, sheet_name=\"Sheet1\", chunksize=chunk_size):\n",
    "    # Chuyển cột 'ngay' sang định dạng datetime\n",
    "    chunk['ngay'] = pd.to_datetime(chunk['ngay'], errors='coerce')\n",
    "    \n",
    "    # Lấy năm từ cột 'ngay'\n",
    "    chunk['year'] = chunk['ngay'].dt.year\n",
    "    \n",
    "    # Lọc dữ liệu từ năm 2016 đến 2023\n",
    "    chunk_filtered = chunk[(chunk['year'] >= 2016) & (chunk['year'] <= 2023)]\n",
    "    \n",
    "    # Thêm dữ liệu vào DataFrame kết hợp\n",
    "    combined_data = pd.concat([combined_data, chunk_filtered], ignore_index=True)\n",
    "\n",
    "# Nhóm dữ liệu theo 'ma' và 'year', tính tổng khối lượng giao dịch\n",
    "annual_volume = combined_data.groupby(['ma', 'year'])['khoiluong'].sum().reset_index()\n",
    "\n",
    "# Sắp xếp dữ liệu theo mã công ty và năm\n",
    "sorted_annual_volume = annual_volume.sort_values(by=['ma', 'year']).reset_index(drop=True)\n",
    "\n",
    "# Xuất dữ liệu ra file Excel hoặc CSV\n",
    "sorted_annual_volume.to_csv(\"tong_khoiluong.csv\", index=False)\n",
    "print(\"Dữ liệu đã được lưu vào tệp 'tong_khoiluong_giaodich_2016_2023.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\minhthao372003\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã chuyển đổi tệp Excel thành CSV: khoiluong_HOSE.csv\n",
      "Dữ liệu đã được lưu vào tệp: D:/data/khoiluongHNX.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Bước 1: Chuyển đổi tệp Excel sang CSV\n",
    "excel_file_path = \"D:/data/khoiluong_HNX.xlsx\"  # Đường dẫn tới tệp Excel\n",
    "csv_file_path = \"khoiluong_HOSE.csv\"  # Đường dẫn tới tệp CSV sau khi chuyển đổi\n",
    "\n",
    "# Đọc Excel và lưu thành CSV\n",
    "pd.read_excel(excel_file_path, sheet_name=\"Sheet1\").to_csv(csv_file_path, index=False)\n",
    "print(f\"Đã chuyển đổi tệp Excel thành CSV: {csv_file_path}\")\n",
    "\n",
    "# Bước 2: Đọc CSV theo từng phần (chunk)\n",
    "chunk_size = 5000  # Số dòng mỗi lần xử lý\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Xử lý dữ liệu trong CSV\n",
    "for chunk in pd.read_csv(csv_file_path, chunksize=chunk_size):\n",
    "    # Chuyển cột 'ngay' sang định dạng datetime\n",
    "    chunk['ngay'] = pd.to_datetime(chunk['ngay'], errors='coerce')\n",
    "    \n",
    "    # Lấy năm từ cột 'ngay'\n",
    "    chunk['year'] = chunk['ngay'].dt.year\n",
    "    \n",
    "    # Lọc dữ liệu từ năm 2016 đến 2023\n",
    "    chunk_filtered = chunk[(chunk['year'] >= 2016) & (chunk['year'] <= 2023)]\n",
    "    \n",
    "    # Thêm dữ liệu vào DataFrame tổng hợp\n",
    "    combined_data = pd.concat([combined_data, chunk_filtered], ignore_index=True)\n",
    "\n",
    "# Nhóm dữ liệu theo 'ma' và 'year', tính tổng khối lượng giao dịch\n",
    "annual_volume = combined_data.groupby(['ma', 'year'])['khoiluong'].sum().reset_index()\n",
    "\n",
    "# Sắp xếp dữ liệu theo mã công ty và năm\n",
    "sorted_annual_volume = annual_volume.sort_values(by=['ma', 'year']).reset_index(drop=True)\n",
    "\n",
    "# Xuất dữ liệu ra tệp Excel\n",
    "output_file_path = \"D:/data/khoiluongHNX.csv\"\n",
    "sorted_annual_volume.to_csv(output_file_path, index=False)\n",
    "print(f\"Dữ liệu đã được lưu vào tệp: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
